{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac5f9906",
   "metadata": {},
   "source": [
    "# üß† K-Nearest Neighbors (KNN) From Scratch\n",
    "\n",
    "Welcome to your clean and well-structured KNN notebook!\n",
    "\n",
    "notebook by Youssef Kotb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba024aca",
   "metadata": {},
   "source": [
    "## üìå 1. Introduction\n",
    "\n",
    "The **K-Nearest Neighbors (KNN)** algorithm is one of the simplest and most intuitive machine learning algorithms. It is a **supervised learning** method used for both **classification** and **regression**, though it is more commonly used for classification.\n",
    "\n",
    "KNN works based on a simple principle:\n",
    "\n",
    "> **\"Tell me who your neighbors are, and I‚Äôll tell you who you are.\"**\n",
    "\n",
    "It predicts the label of a new data point by looking at the **K closest points** in the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49911fb8",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Images/guess class.png\" width=\"750\"><br>\n",
    "  <em>Figure 1: try to guess the class of the black dot</em>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0408e6ed",
   "metadata": {},
   "source": [
    "## üìå 2. How KNN Works\n",
    "\n",
    "KNN follows these steps:\n",
    "\n",
    "1. Choose a value for **K** (number of neighbors).\n",
    "2. Calculate the **distance** between the new point and all training points.\n",
    "3. Select the **K nearest neighbors**.\n",
    "4. Perform **majority voting** (for classification) or averaging (for regression).\n",
    "5. Output the predicted value.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå 3. Distance Metrics\n",
    "\n",
    "The most commonly used distance metric:\n",
    "\n",
    "### **Euclidean Distance**\n",
    "\n",
    "$$ d(p, q) = \\sqrt{\\sum_{i=1}^{n} (p_i - q_i)^2 } $$\n",
    "\n",
    "Other distance metrics:\n",
    "\n",
    "* Manhattan Distance\n",
    "* Minkowski Distance\n",
    "* Cosine Similarity\n",
    "\n",
    "In this notebook, we'll use **Euclidean distance**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå 4. Advantages and Disadvantages\n",
    "\n",
    "### ‚úÖ **Advantages:**\n",
    "\n",
    "* Simple to understand and implement\n",
    "* No training time\n",
    "* Works well for small datasets\n",
    "\n",
    "### ‚ùå **Disadvantages:**\n",
    "\n",
    "* Slow prediction for large datasets\n",
    "* Sensitive to irrelevant features\n",
    "* Choice of K can significantly affect performance\n",
    "\n",
    "---\n",
    "\n",
    "## üìå 5. Choosing the Best Value of K\n",
    "\n",
    "To choose K, you can:\n",
    "\n",
    "* Try odd values (to avoid ties)\n",
    "* Use cross-validation\n",
    "* Plot accuracy vs K\n",
    "\n",
    "Typically, a small K can lead to **overfitting**, while a large K can lead to **underfitting**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå 6. Conclusion\n",
    "\n",
    "You have built a complete **KNN algorithm from scratch**, understood how it works, and tested it on data. This foundational knowledge will help you understand many other ML algorithms.\n",
    "\n",
    "Feel free to extend this project by:\n",
    "\n",
    "* Adding regression support\n",
    "* Adding different distance metrics\n",
    "* Adding weighted voting\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
